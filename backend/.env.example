# 环境变量示例文件（可提交到 GitHub）
# 复制此文件为 .env 并填入实际值，.env 已在 .gitignore 中忽略

# 服务配置
HOST=0.0.0.0
PORT=8000
DEBUG=true

# ========== 各模型 API Key（可选，配置后启动时自动加入可用模型列表）==========
# OpenAI（GPT 系列）
# OPENAI_API_KEY=sk-xxx

# Anthropic（Claude 系列）
# ANTHROPIC_API_KEY=sk-ant-xxx

# DeepSeek
# DEEPSEEK_API_KEY=sk-xxx

# 通义千问（阿里云）
# QWEN_API_KEY=sk-xxx

# Kimi（月之暗面 Moonshot）
# MOONSHOT_API_KEY=sk-xxx

# GLM（智谱 / 智谱 AI）
# ZHIPU_API_KEY=xxx

# Gemini（Google）
# GEMINI_API_KEY=xxx

# ========== 可选：单独指定默认模型（覆盖上述自动选择的默认模型）==========
# DEFAULT_MODEL_ID=default
# DEFAULT_MODEL_NAME=DeepSeek Chat
# DEFAULT_MODEL_PROVIDER=deepseek
# DEFAULT_MODEL_MODEL_NAME=deepseek-chat
# DEFAULT_MODEL_API_KEY=
# DEFAULT_MODEL_API_BASE=
# DEFAULT_MODEL_MAX_TOKENS=4096
# DEFAULT_MODEL_TEMPERATURE=0.7

# ========== MinIO 对象存储（infra/docker-compose 启动后使用）==========
# MINIO_ENDPOINT=localhost:9000
# MINIO_ACCESS_KEY=minioadmin
# MINIO_SECRET_KEY=minioadmin
# MINIO_BUCKET=aiweb
# MINIO_SECURE=false

# ========== Redis（infra/docker-compose 启动后使用）==========
# REDIS_HOST=localhost
# REDIS_PORT=6379
# REDIS_DB=0
# REDIS_PASSWORD=

# ========== JWT 认证（登录签发 token）==========
# 生产环境必须设置足够长且随机的 JWT_SECRET（建议 32 字符以上）
# JWT_SECRET=your-random-secret-at-least-32-chars
# JWT_ALGORITHM=HS256
# JWT_EXPIRE_SECONDS=86400

# ========== PostgreSQL（infra/docker-compose 启动后使用）==========
# POSTGRES_HOST=localhost
# POSTGRES_PORT=5432
# POSTGRES_USER=aiweb
# POSTGRES_PASSWORD=aiweb
# POSTGRES_DB=aiweb

# ========== Milvus（infra/docker-compose 启动后使用）==========
# MILVUS_HOST=localhost
# MILVUS_PORT=19530

# ========== RabbitMQ（infra/docker-compose 启动后使用）==========
# RABBITMQ_HOST=localhost
# RABBITMQ_PORT=5672
# RABBITMQ_USER=guest
# RABBITMQ_PASSWORD=guest
# RABBITMQ_VHOST=/

# ========== Elasticsearch（infra/docker-compose 启动后使用）==========
# ELASTICSEARCH_HOST=localhost
# ELASTICSEARCH_PORT=9200

# ========== RAG 知识库（与 memory 模块共用 Embedding）==========
# 默认使用通义千问 text-embedding-v4（与记忆模块一致）
# RAG_EMBEDDING_MODEL=  # 留空则用 MEMORY_EMBEDDING_MODEL 或 text-embedding-v4
# RAG_EMBEDDING_DIM=1536  # 向量维度，需与 Milvus schema 一致
# RAG_EMBEDDING_BASE_URL=  # 配置则覆盖为自定义端点，需同时配 RAG_EMBEDDING_API_KEY
# Reranker 精排（可选，配置 JINA_API_KEY 时使用 Jina Cross-Encoder）
# JINA_API_KEY=
# RAG_RERANKER_MODEL=jina-reranker-v3
# Reranker 双阈值（Jina 与 Embedding 降级量纲不同，必须分离）
# RAG_RERANK_THRESHOLD=0.2  # Jina Cross-Encoder 及格线
# RAG_FALLBACK_COSINE_THRESHOLD=0.85  # Embedding 降级时余弦相似度及格线
# Sparse 神经稀疏向量（TF-IDF 仅作降级，无语义扩展）
# RAG_SPARSE_PROVIDER=auto  # auto | bge_m3 | api
# RAG_SPARSE_EMBEDDING_URL=  # BGE-M3/SPLADE 推理服务，如 http://localhost:8001/encode
# RAG_SPARSE_BGE_M3_MODEL=BAAI/bge-m3  # 本地 BGE-M3 模型（需 pip install FlagEmbedding）
# 巨型 Chunk 护栏（超过此 token 数截断用于 Embedding，完整内容仍用于检索）
# RAG_MAX_EMBEDDING_TOKENS=2048
# 异步任务队列（长耗时解析入队，需 Redis + Worker）
# RAG_USE_QUEUE=false  # true 时 POST /process 立即返回，需运行 python -m scripts.rag_worker

# ========== 多格式解析 ==========
# PDF: 优先 MinerU 外部 API（mineru.net），未配置 token 或失败时用本地 MinerU / pdfplumber
# 外部 API 文档: https://mineru.net/apiManage/docs
# MINERU_EXTERNAL_API_BASE_URL=https://mineru.net
# MINERU_API_TOKEN=                    # 在 mineru.net 申请，配置后 RAG 文件识别优先走外部 API
# MINERU_EXTERNAL_MODEL_VERSION=       # 可选: pipeline | vlm | MinerU-HTML，不填则按 MINERU_BACKEND 推断
#
# ----- 可选：仅在使用 mineru.net 云端解析 PDF 时需要 -----
# mineru.net 需通过公网 URL 拉取你的文件，因此要把本机 MinIO 暴露到公网（如 ngrok / cloudflared）。
# 不配置 MINIO_PUBLIC_ENDPOINT 时，RAG 使用本地 MinerU(9999) 或 pdfplumber，无需公网暴露。
# 配置步骤：1) 运行 ngrok http 9000 或 cloudflared tunnel --url http://localhost:9000
#          2) 将得到的 https://xxxx.ngrok-free.app 填入下方（不要带末尾斜杠）
# MINIO_PUBLIC_ENDPOINT=https://xxxx.ngrok-free.app
# 本地 MinerU Web API（对应 docker-compose 中的 9999 端口，外部 API 未配置或失败时使用）
# MINERU_API_BASE_URL=http://localhost:9999
# MinerU 解析后端: pipeline（默认）| vlm-auto-engine | hybrid-auto-engine
# MINERU_BACKEND=pipeline

# 图片工业级 Pipeline（需 MinerU 在 block 中提供 b64_image/image_bytes）
# 开启后：VLM 初筛 → FLOWCHART/CHART/PHOTO 专家分支 → 融合注入 block.text 再切块
# 图片 Pipeline：统一 Qwen 3.5 Plus（初筛 + 流程图/图表/照片）
# RAG_IMAGE_PIPELINE_ENABLE=false
# RAG_IMAGE_PIPELINE_TIMEOUT=30
# RAG_IMAGE_VLM_MODEL=qwen3-vl-plus   # 默认 qwen3-vl-plus
# RAG_IMAGE_TRIAGE_MODEL=             # 可选，覆盖初筛模型
# RAG_IMAGE_VLM_BASE_URL=             # 可选，不填则用 QWEN_API_BASE；API Key 统一用 QWEN_API_KEY
# RAG_IMAGE_CHART_MAX_TOKENS=1500   # 图表分支 VLM 输出截断上限

# Word/Excel/MD/TXT: 本地解析 (python-docx, pandas, openpyxl)
# MP3/WAV 等音频: OpenAI Whisper API 转写（需 OPENAI_API_KEY 或 QWEN_API_KEY）

